<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Multi-Agent Reinforcement Learning for Inverse Design in Photonic Integrated Circuits</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Multi-Agent Reinforcement Learning for Inverse Design in Photonic Integrated Circuits</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://ymahlau.github.io/" target="_blank">Yannik Mahlau</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="https://www.tnt.uni-hannover.de/en/staff/schier/" target="_blank">Maximilian Schier</a>, </span>
                  <span class="author-block">
                    <a href="https://www.tnt.uni-hannover.de/staff/reinders/" target="_blank">Christop Reinders</a>, 
                  </span>
                  <span class="author-block">
                    <a href="https://www.tnt.uni-hannover.de/staff/schubert/" target="_blank">Frederik Schubert</a>, 
                  </span>
                  <span class="author-block">
                    Marco Bügling, 
                  </span>
                  <span class="author-block">
                    <a href="https://www.tnt.uni-hannover.de/en/staff/rosenhahn/" target="_blank">Bodo Rosenhahn</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Institute of Information Processing, Leibniz University Hannover<br>Reinforcement Learning Conference 2025</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2506.18627" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/ymahlau/blend" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2506.18627" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img poster="" id="tree" height="100%" src="static/images/teaser.png">
      <h2 class="subtitle has-text-justified">
        Design task of a linear operation on a photonic integrated circuit. In the left image, 65% of the incoming light emitted by a source (yellow) in the left waveguide (blue) should be routed to the top right waveguide (blue), while 35% of the light should go to the bottom right waveguide (blue). Transmission is measured as the ratio between output- (green) and input-detector (pink). The design task is a binary optimization problem for choosing silicon or air at every voxel. In the middle image, an electromagnetic simulation of the design is shown. During optimization (right), gradient descent gets stuck in a local minimum, while our BPPO and BAC show better exploration behavior.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Inverse design of photonic integrated circuits (PICs) has traditionally relied on gradientbased optimization. However, this approach is prone to end up in local minima, which results in suboptimal design functionality. As interest in PICs increases due to their potential for addressing modern hardware demands through optical computing, more adaptive optimization algorithms are needed. We present a reinforcement learning (RL) environment as well as multi-agent RL algorithms for the design of PICs. By discretizing the design space into a grid, we formulate the design task as an optimization problem with thousands of binary variables. We consider multiple two- and three-dimensional design tasks that represent PIC components for an optical computing system. By decomposing the design space into thousands of individual agents, our algorithms are able to optimize designs with only a few thousand environment samples. They outperform previous state-of-the-art gradient-based optimization in both two- and threedimensional design tasks. Our work may also serve as a benchmark for further exploration of sample-efficient RL for inverse design in photonics.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->



<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Topology Optimization with Reinforcement Learning</h2>
      <div class="content is-centered has-text-centered">
        <img poster="" id="tree" width="50%" src="static/images/agents.png">
      </div>
      <div class="content has-text-justified">
        <p>
          In topology optimization, the goal is to find the best material distribution for a given task. We discretize the design space and control each part with a separate agent, each faces a binary choice: place material or air at the respective chunk of the design space. This setting is similar to a hierarchical bandit where N agents choose k actions. However, the major challenge is sample efficiency. Evaluating the reward of a joint action from all agents requires a full electromagnetic simulation, which can take between multiple seconds up to multiple minutes. Therefore, multiple thousands of agents need to learn to cooperate using only few samples.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Results</h2>
      <div class="content is-centered has-text-centered">
        <img poster="" id="tree" width="75%" src="static/images/results.png">
      </div>
      <div class="content has-text-justified">
        <p>
          We test the feasibility of MARL in several topology optimization tasks for optical computing. Our Bandit variants of PPO (BPPO) and the Actor-Critic approach (BAC) consistently outperform all baselines by a large margin. Most importantly, gradient based optimization (Grad) is the standard procedure in topology optimization, but is very prone to get stuck in local minima. Additionally, gradient-based optimization struggles with three-dimensional topology optimization, because the non-differentiable design constraints impede the optimization process. In contrast, MARL can easily incorporate these design constraints directly in the optimization process.
        </p>
      </div>
    </div>
  </div>
</section>


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="content is-centered has-text-centered">
        <video poster="" id="tree" autoplay controls muted loop height="100%">
          <source src="static/videos/video_demonstration.mp4" type="video/mp4">
        </video>
      </div>
      <div class="content has-text-justified">
        <p>
          We test the feasibility of MARL in several topology optimization tasks for optical computing. Our Bandit variants of PPO (BPPO) and the Actor-Critic approach (BAC) consistently outperform all baselines by a large margin. Most importantly, gradient based optimization (Grad) is the standard procedure in topology optimization, but is very prone to get stuck in local minima. Additionally, gradient-based optimization struggles with three-dimensional topology optimization, because the non-differentiable design constraints impede the optimization process. In contrast, MARL can easily incorporate these design constraints directly in the optimization process.
        </p>
      </div>
    </div>
  </div>
</section>



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <p>This preprint citation will be replaced with conference paper as soon as RLC publishes it:</p>
      <pre>
<code>@article{mahlau2025multi,
  title={Multi-Agent Reinforcement Learning for Inverse Design in Photonic Integrated Circuits},
  author={Mahlau, Yannik and Schier, Maximilian and Reinders, Christoph and Schubert, Frederik and B{\"u}gling, Marco and Rosenhahn, Bodo},
  journal={arXiv preprint arXiv:2506.18627},
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
